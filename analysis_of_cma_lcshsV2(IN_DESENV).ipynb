{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "analysis_of_cma_lcshsV2(IN DESENV).ipynb",
      "authorship_tag": "ABX9TyORR52oV4nKi5fYuECiegct",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tiagochavo87/LCSH_analysis/blob/main/analysis_of_cma_lcshsV2(IN_DESENV).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the data from the CSV file\n",
        "data = pd.read_csv(\"LOH.csv\", sep=\";\")\n",
        "\n",
        "# Apply a filter to exclude chromosomes X and Y\n",
        "data = data.loc[(data['Chrom'] != 'X') & (data['Chrom'] != 'Y')]\n",
        "\n",
        "# Replace dots and convert Tamanho column to integer type\n",
        "data['Tamanho'] = data['Tamanho'].str.replace('.', '').astype(int)\n",
        "\n",
        "# Filter data for autosomes with a size greater than 10,000,000\n",
        "data_autosomes = data.loc[data['Chrom'].str.contains('^([1-9]|[1-9][0-9])$')]\n",
        "data_autosomes = data_autosomes[data_autosomes['Tamanho'] > 10000000]\n",
        "\n",
        "# Write the autosomes data to a new CSV file\n",
        "data_autosomes.to_csv('LCSHs_>_10.csv', sep=';', index=False)\n",
        "\n",
        "# Filter data for regions with size greater than or equal to 3,000,000\n",
        "data = data[data['Tamanho'] >= 3000000]\n",
        "\n",
        "# Filter data for regions with sizes between 3,000,000 and 5,000,000\n",
        "data_3_5 = data[(data['Tamanho'] > 3000000) & (data['Tamanho'] <= 5000000)]\n",
        "\n",
        "# Write the 3-5 MB regions data to a new CSV file\n",
        "data_3_5.to_csv('LCSHs_>_3_<_5.csv', sep=';', index=False)\n",
        "\n",
        "# Filter data for 3-5 MB regions with a total size of at least 10,000,000 and only one region per file\n",
        "data_3_5 = data_3_5.groupby('File').filter(lambda x: len(x) == 1 and x['Tamanho'].sum() >= 10000000)\n",
        "\n",
        "# Filter data for regions with size greater than 5,000,000\n",
        "data_5 = data[data['Tamanho'] > 5000000]\n",
        "\n",
        "# Filter data for regions with a total size of at least 10,000,000 and only one chromosome per file\n",
        "data_5 = data_5.groupby('File').filter(lambda x: len(x.groupby('Chrom')) == 1 and x['Tamanho'].sum() >= 10000000)\n",
        "\n",
        "# Write the 5 MB regions data to a new CSV file\n",
        "data_5.to_csv('possibles_UPDs.csv', sep=';', index=False)\n",
        "\n",
        "# Filter data for cases with at least one LCSH greater than 5 MB\n",
        "data_5_mb = data[data['Tamanho'] > 5000000]\n",
        "data_5_mb = data_5_mb.groupby('File').filter(lambda x: x[x['Tamanho'] >= 5000000].shape[0] > 0)\n",
        "\n",
        "# Print all cases with LCSHs greater than 5 MB to a CSV file\n",
        "data_5_mb.to_csv('LCSHs_>_5.csv', sep=';', index=False)\n",
        "\n",
        "# Sum LCSHs greater than 3 MB for each case\n",
        "sum_lcshs = data[data['Tamanho'] >= 3000000].groupby('File')['Tamanho'].sum()\n",
        "\n",
        "# Create a new DataFrame with case names and total LCSHs greater than 3 MB\n",
        "output = pd.DataFrame({'File': sum_lcshs.index, 'Total LCSHs > 3MB': sum_lcshs.values})\n",
        "\n",
        "# Write the output DataFrame to a CSV file\n",
        "output.to_csv('total_lcshs.csv', sep=';', index=False)\n",
        "\n",
        "# Calculate the total size of human autosomal DNA\n",
        "total_autosomal_dna = 2881000000\n",
        "\n",
        "# Calculate the proportion of LCSHs greater than 3 MB for each case\n",
        "proportions = []\n",
        "for file, size in sum_lcshs.items():\n",
        "    proportion = size / total_autosomal_dna\n",
        "    proportions.append({'File': file, 'Total LCSHs > 3MB': size, 'Proportion of LCSHs > 3MB to Autosomal DNA': proportion})\n",
        "\n",
        "# Create a new DataFrame with the proportion for each case\n",
        "proportions_df = pd.DataFrame(proportions)\n",
        "\n",
        "# Write the output DataFrame to a CSV file\n",
        "proportions_df.to_csv('lcsh_proportions.csv', sep=';', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRe5zTgCdZTP",
        "outputId": "d8670c4c-e344-4495-e3fd-53053cc9632b"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-123-6cb181c1a486>:10: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  data['Tamanho'] = data['Tamanho'].str.replace('.', '').astype(int)\n",
            "<ipython-input-123-6cb181c1a486>:13: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
            "  data_autosomes = data.loc[data['Chrom'].str.contains('^([1-9]|[1-9][0-9])$')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code imports the NumPy and Pandas libraries and uses them to calculate inbreeding coefficients based on certain proportions of data.\n",
        "\n",
        "The first step is to define an array of values for F (inbreeding coefficient) that the code will use. These values are defined as percentages and then divided by 100.\n",
        "\n",
        "Next, the code reads in a CSV file containing proportions of data and stores them in a Pandas DataFrame.\n",
        "\n",
        "Then, the code iterates through each row of the DataFrame and calculates the F value that is closest to the proportion of LCSHs (Library of Congress Subject Headings) greater than 3MB to Autosomal DNA. This is done using NumPy's argmin() function to find the index of the closest F value in the array.\n",
        "\n",
        "After calculating the closest F value for each row, the code creates a new Pandas DataFrame with the data transposed so that the F values are columns and the file names are rows.\n",
        "\n",
        "Finally, the transposed DataFrame is written to a new CSV file along with the original proportions DataFrame.\n",
        "\n",
        "Overall, this code is useful for calculating inbreeding coefficients based on specific proportions of data, which can be helpful in genetic research.\n",
        "\n",
        "Output:\n",
        "There are two output files: 'lcsh_transposed_proportions.csv' and 'inbreeding_coefficients.csv'. The first file contains the transposed proportions DataFrame, and the second file contains the original proportions DataFrame with an additional column for the closest F value.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "amRV7uJM5-o7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the F values\n",
        "f_values = np.array([0.5, 1.5, 3, 6, 12.5, 25]) / 100\n",
        "\n",
        "# Get the data proportions\n",
        "proportions = pd.read_csv('lcsh_proportions.csv', sep=';')\n",
        "\n",
        "# Calculate the F values closest to the proportions\n",
        "for index, row in proportions.iterrows():\n",
        "    proportion = row['Proportion of LCSHs > 3MB to Autosomal DNA']\n",
        "    closest_f = f_values[np.abs(f_values - proportion).argmin()]\n",
        "    proportions.at[index, 'Inbreeding Coefficient (F)'] = closest_f\n",
        "\n",
        "# Transpose the cases to the columns corresponding to the F values\n",
        "transposed_proportions = pd.DataFrame(columns=['File', '0.5%', '1.5%', '3%', '6%', '12.5%', '25%'])\n",
        "for index, row in proportions.iterrows():\n",
        "    file = row['File']\n",
        "    f_value = row['Inbreeding Coefficient (F)']\n",
        "    transposed_proportions.at[index, 'File'] = file\n",
        "    transposed_proportions.at[index, f'{f_value*100:.1f}%'] = row['Proportion of LCSHs > 3MB to Autosomal DNA']\n",
        "\n",
        "# Write the transposed DataFrame to a new CSV file\n",
        "transposed_proportions.to_csv('lcsh_transposed_proportions.csv', sep=';', index=False)\n",
        "\n",
        "# Write the output DataFrame to a CSV file\n",
        "proportions.to_csv('inbreeding_coefficients.csv', sep=';', index=False)\n"
      ],
      "metadata": {
        "id": "lzniRUaB3mQ2"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Carrega tabela de dados\n",
        "df = pd.read_csv(\"LCSHs_>_3_<_5.csv\", sep=\";\")\n",
        "\n",
        "# Extrai coordenadas genÃ´micas da coluna 'Microarray Nome..'\n",
        "chrom_pos = []\n",
        "for name in df['Microarray Nome..']:\n",
        "    match = re.search(r'\\d+[pq]\\d+(\\.\\d+)?[pq]\\d+(\\.\\d+)?\\((\\d+)-(\\d+)\\)', name)\n",
        "    if match:\n",
        "        chrom, start, end = match.group(0).split()[1].split('(')[0].split('-')\n",
        "        chrom_pos.append((chrom, int(start), int(end)))\n",
        "    else:\n",
        "        chrom_pos.append(None)\n",
        "df['chrom_pos'] = chrom_pos\n",
        "\n",
        "# Divide coordenadas por cromossomos\n",
        "chrom_dict = {}\n",
        "for chrom_pos_tuple in chrom_pos:\n",
        "    if chrom_pos_tuple:\n",
        "        chrom, start, end = chrom_pos_tuple\n",
        "        if chrom not in chrom_dict:\n",
        "            chrom_dict[chrom] = []\n",
        "        chrom_dict[chrom].append((start, end))\n",
        "\n",
        "# Loop pelos cromossomos\n",
        "threshold = 0.005  # FraÃ§Ã£o mÃ­nima de amostras com trechos de homozygose\n",
        "homozygous_dict = {}\n",
        "for chrom, coords in chrom_dict.items():\n",
        "    total_samples = len(df)\n",
        "    \n",
        "    # Filtra amostras apenas para o cromossomo atual\n",
        "    chrom_df = df[df['chrom_pos'].apply(lambda x: x[0] if x else None) == chrom]\n",
        "    \n",
        "    homozygous_samples = 0\n",
        "    window_size = 1000000  # Tamanho da janela para detecÃ§Ã£o de trechos de homozygose\n",
        "    for start, end in coords:\n",
        "        window_start = start\n",
        "        while window_start < end:\n",
        "            window_end = min(window_start + window_size, end)\n",
        "            samples = chrom_df[(chrom_df['chrom_pos'] == (chrom, window_start, window_end)) & (chrom_df['Call Rate'] >= 0.95)]\n",
        "            if len(samples) > 0 and all(samples['B Allele Freq'].round(2).duplicated()):\n",
        "                homozygous_samples += len(samples)\n",
        "            window_start = window_end\n",
        "    homozygous_fraction = homozygous_samples / len(chrom_df)\n",
        "    if homozygous_fraction > threshold:\n",
        "        homozygous_dict[chrom] = homozygous_fraction\n",
        "\n",
        "# Gera nova tabela CSV com informaÃ§Ãµes de cromossomos e fraÃ§Ãµes de amostras com trechos de homozygose\n",
        "homozygous_df = pd.DataFrame({'Chromosome': list(homozygous_dict.keys()), 'Homozygous Fraction': list(homozygous_dict.values())})\n",
        "homozygous_df.to_csv('homozygous_regions.csv', index=False)\n"
      ],
      "metadata": {
        "id": "DUfC-U5LM2w1"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Carrega o arquivo CSV\n",
        "df = pd.read_csv(\"LCSHs_>_3_<_5.csv\", sep=\";\")\n",
        "# Extrai as informaÃ§Ãµes da coluna \"Microarray Nome..\"\n",
        "df['start'] = df['Microarray Nome..'].str.extract('\\((.*?)\\-')\n",
        "df['end'] = df['Microarray Nome..'].str.extract('\\-(.*?)\\)')\n",
        "\n",
        "def extract_coordinates(row):\n",
        "    pattern = r'\\((\\d+,?\\d*)-(\\d+,?\\d*)\\)'\n",
        "    match = re.search(pattern, row)\n",
        "    if match:\n",
        "        start = match.group(1).replace(',', '.')\n",
        "        end = match.group(2).replace(',', '.')\n",
        "        return pd.Series([start, end])\n",
        "    else:\n",
        "        return pd.Series(['', ''])\n",
        "\n",
        "# Remove a coluna original\n",
        "df.drop('Microarray Nome..', axis=1, inplace=True)\n",
        "\n",
        "# Cria uma nova dataframe com as colunas \"Chrom\", \"cytoband\", \"start\" e \"end\"\n",
        "new_df = pd.DataFrame({\n",
        "    'Chrom': df['Chrom'],\n",
        "    'cytoband': df['cytoband'],\n",
        "    'start': df['start'],\n",
        "    'end': df['end']\n",
        "})\n",
        "\n",
        "def extract_coordinates(row):\n",
        "    pattern = r'\\((\\d+,?\\d*)-(\\d+,?\\d*)\\)'\n",
        "    match = re.search(pattern, row)\n",
        "    if match:\n",
        "        start = match.group(1).replace(',', '.')\n",
        "        end = match.group(2).replace(',', '.')\n",
        "        return pd.Series([start, end])\n",
        "    else:\n",
        "        return pd.Series(['', ''])\n",
        "\n",
        "new_df['start'] = new_df['start'].replace(',', '', regex=True)\n",
        "new_df['end'] = new_df['end'].replace(',', '', regex=True)\n",
        "\n",
        "# Salva a nova dataframe em um arquivo CSV\n",
        "new_df.to_csv('nova_dataframe_fron.csv', sep=\";\", index=False, decimal='.')\n",
        "\n"
      ],
      "metadata": {
        "id": "OLmIC-EGVIaH"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P1_mdSw1PYvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjZPx6gCN--c",
        "outputId": "b3feb6cd-ea3c-44f6-b2a1-7226a218971a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   chrom  start        end  n_windows\n",
            "0      1      0  249250621     249250\n",
            "1      2      0  243199373     243199\n",
            "2      3      0  198022430     198022\n",
            "3      4      0  191154276     191154\n",
            "4      5      0  180915260     180915\n",
            "5      6      0  171115067     171115\n",
            "6      7      0  159138663     159138\n",
            "7      8      0  146364022     146364\n",
            "8      9      0  141213431     141213\n",
            "9     10      0  135534747     135534\n",
            "10    11      0  135006516     135006\n",
            "11    12      0  133851895     133851\n",
            "12    13      0  115169878     115169\n",
            "13    14      0  107349540     107349\n",
            "14    15      0  102531392     102531\n",
            "15    16      0   90354753      90354\n",
            "16    17      0   81195210      81195\n",
            "17    18      0   78077248      78077\n",
            "18    19      0   59128983      59128\n",
            "19    20      0   63025520      63025\n",
            "20    21      0   48129895      48129\n",
            "21    22      0   51304566      51304\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Definir um dicionÃ¡rio com as informaÃ§Ãµes de inÃ­cio e fim de cada cromossomo\n",
        "chromosomes = {\n",
        "    'chr1': {'start': 0, 'end': 249250621},\n",
        "    'chr2': {'start': 0, 'end': 243199373},\n",
        "    'chr3': {'start': 0, 'end': 198022430},\n",
        "    'chr4': {'start': 0, 'end': 191154276},\n",
        "    'chr5': {'start': 0, 'end': 180915260},\n",
        "    'chr6': {'start': 0, 'end': 171115067},\n",
        "    'chr7': {'start': 0, 'end': 159138663},\n",
        "    'chr8': {'start': 0, 'end': 146364022},\n",
        "    'chr9': {'start': 0, 'end': 141213431},\n",
        "    'chr10': {'start': 0, 'end': 135534747},\n",
        "    'chr11': {'start': 0, 'end': 135006516},\n",
        "    'chr12': {'start': 0, 'end': 133851895},\n",
        "    'chr13': {'start': 0, 'end': 115169878},\n",
        "    'chr14': {'start': 0, 'end': 107349540},\n",
        "    'chr15': {'start': 0, 'end': 102531392},\n",
        "    'chr16': {'start': 0, 'end': 90354753},\n",
        "    'chr17': {'start': 0, 'end': 81195210},\n",
        "    'chr18': {'start': 0, 'end': 78077248},\n",
        "    'chr19': {'start': 0, 'end': 59128983},\n",
        "    'chr20': {'start': 0, 'end': 63025520},\n",
        "    'chr21': {'start': 0, 'end': 48129895},\n",
        "    'chr22': {'start': 0, 'end': 51304566},\n",
        "}\n",
        "\n",
        "# Criar uma DataFrame a partir do dicionÃ¡rio de cromossomos e adicionar o cabeÃ§alho \"chrom\" Ã  coluna de Ã­ndices\n",
        "chromosomes_df = pd.DataFrame.from_dict(chromosomes, orient='index', columns=['start', 'end'])\n",
        "chromosomes_df = chromosomes_df.rename_axis('chrom').reset_index()\n",
        "# Substituir \"chr\" pelo valor numÃ©rico do cromossomo na coluna \"chrom\"\n",
        "chromosomes_df['chrom'] = chromosomes_df['chrom'].replace('chr', '', regex=True)\n",
        "# Definir a janela de anÃ¡lise como sendo de 1 kilobase (1000 pares de base)\n",
        "window_size = 1000\n",
        "chromosomes_df['n_windows'] = ((chromosomes_df['end'] - chromosomes_df['start']) / window_size).astype(int)\n",
        "\n",
        "print(chromosomes_df)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ler o arquivo CSV\n",
        "data = pd.read_csv('LOH.csv', sep=';')\n",
        "\n",
        "# Contar a quantidade de valores Ãºnicos na coluna \"File\"\n",
        "file_count = data['File'].nunique()\n",
        "\n",
        "# Imprimir o total de casos \"File\"\n",
        "print(f\"O total de casos na coluna 'File' Ã©: {file_count}\")\n",
        "\n",
        "# Armazenar o resultado em uma variÃ¡vel\n",
        "result = pd.DataFrame({'Total de casos': [file_count]})\n",
        "\n",
        "# Salvar o resultado em um arquivo CSV\n",
        "result.to_csv('output.csv', index=False)\n",
        "\n",
        "# Imprimir o resultado\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "Mt-d62ocmygS",
        "outputId": "c17d2f4c-e9d9-4692-cf76-39a75b39ef0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O total de casos na coluna 'File' Ã©: 417\n",
            "   Total de casos\n",
            "0             417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ler o arquivo nova_dataframe_fron6.csv\n",
        "df = pd.read_csv('nova_dataframe_fron.csv', sep=\";\", decimal='.')\n",
        "\n",
        "# Renomear as colunas\n",
        "df = df.rename(columns={'Chrom': 'chrom', 'start': 'start_pos', 'end': 'end_pos'})\n",
        "# Mesclar as informaÃ§Ãµes dos cromossomos com as coordenadas genÃ´micas\n",
        "chromosomes_df['chrom'] = chromosomes_df['chrom'].astype(int)\n",
        "\n",
        "merged_df = pd.merge(df, chromosomes_df, on='chrom', how='inner')\n",
        "# Calcular as regiÃµes genÃ´micas de interesse\n",
        "merged_df['start_region'] = merged_df['start'] + ((merged_df['start_pos'] - 1) // window_size) * window_size\n",
        "merged_df['end_region'] = merged_df['end'] - (merged_df['end'] - merged_df['end_pos']) % window_size\n",
        "# Selecionar as colunas de interesse\n",
        "result2 = merged_df[['chrom', 'cytoband', 'start_region', 'end_region']]\n",
        "\n",
        "# Salvar o resultado em um arquivo CSV\n",
        "result2.to_csv('output_regions.csv', sep= \";\")\n"
      ],
      "metadata": {
        "id": "1A5jl1knBUgA"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ler o arquivo de saÃ­da anterior com as regiÃµes genÃ´micas\n",
        "regions = pd.read_csv('output_regions.csv', sep=';')\n",
        "\n",
        "# Contar a ocorrÃªncia de cada regiÃ£o genÃ´mica\n",
        "counts = regions.value_counts(['chrom', 'start_region', 'end_region'])\n",
        "\n",
        "# Obter o total de casos\n",
        "total_cases = pd.read_csv('output.csv')['Total de casos'][0]\n",
        "\n",
        "# Calcular a frequÃªncia relativa de cada regiÃ£o genÃ´mica\n",
        "freq = counts / total_cases\n",
        "\n",
        "# Salvar o resultado em um arquivo CSV\n",
        "freq.to_csv('output_frequency.csv', sep=';')\n"
      ],
      "metadata": {
        "id": "H9vdDgbkEdK5"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agrupar as regiÃµes por cromossomo, citobanda, tamanho final e calcular a frequÃªncia\n",
        "grouped = merged_df.groupby(['chrom', 'cytoband', 'start_region', 'end_region']).size().reset_index(name='count')\n",
        "grouped['freq'] = grouped['count'] / file_count\n",
        "\n",
        "# Selecionar apenas as regiÃµes com frequÃªncia igual ou maior que 5%\n",
        "freq_5 = grouped[grouped['freq'] >= 0.005]\n",
        "\n",
        "# Incluir o tamanho final das regiÃµes\n",
        "freq_5['size'] = freq_5['end_region'] - freq_5['start_region']\n",
        "\n",
        "# Selecionar as colunas de interesse\n",
        "result3 = freq_5[['chrom', 'cytoband', 'start_region', 'end_region', 'size', 'freq']]\n",
        "\n",
        "# Salvar o resultado em um arquivo CSV\n",
        "result3.to_csv('output_regions_freq_5.csv', sep=\";\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cKyV3cbI-Uf",
        "outputId": "a65a61d4-c4c0-4160-af10-307bce0b4571"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-152-496d88841151>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  freq_5['size'] = freq_5['end_region'] - freq_5['start_region']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular a frequÃªncia de cada regiÃ£o genÃ´mica\n",
        "freq = result2.groupby(['chrom', 'start_region', 'end_region']).size().reset_index(name='frequencia')\n",
        "freq['frequencia'] = freq['frequencia'] / file_count\n",
        "\n",
        "# Selecionar as regiÃµes com frequÃªncia igual ou maior que 5%\n",
        "freq_5 = freq[freq['frequencia'] >= 0.005]\n",
        "\n",
        "# Salvar o resultado em um arquivo CSV\n",
        "freq_5.to_csv('output_freq_5.csv', sep=';', index=False)\n"
      ],
      "metadata": {
        "id": "gYCk79WGFAoJ"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result3)"
      ],
      "metadata": {
        "id": "ShQ9Z6fpsU5d",
        "outputId": "27edeafd-14e1-48aa-99f1-c9a428f9ca20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     chrom cytoband  start_region  end_region       size      freq\n",
            "46       1    q21.1     144077000   249250533  105173533  0.026379\n",
            "116      2    q11.1      95341000   243198664  147857664  0.007194\n",
            "456     11    p11.2      47885000   135005787   87120787  0.014388\n",
            "457     11    p11.2      47910000   135005636   87095636  0.040767\n",
            "466     11    p11.2      48144000   135005636   86861636  0.007194\n",
            "593     16    p11.2      30877000    90354544   59477544  0.007194\n",
            "603     16    p11.2      31356000    90354544   58998544  0.009592\n",
            "605     16    p11.2      31376000    90354544   58978544  0.007194\n",
            "606     16    p11.2      31386000    90354544   58968544  0.007194\n",
            "607     16    p11.2      31397000    90354544   58957544  0.009592\n",
            "613     16    p11.2      31460000    90354544   58894544  0.011990\n",
            "617     16    p11.2      31542000    90354544   58812544  0.021583\n",
            "618     16    p11.2      31554000    90354544   58800544  0.009592\n",
            "620     16    p11.2      31576000    90354544   58778544  0.016787\n",
            "622     16    p11.2      31587000    90354544   58767544  0.059952\n",
            "624     16    p11.2      31609000    90354544   58745544  0.057554\n",
            "626     16    p11.2      31621000    90354544   58733544  0.016787\n",
            "627     16    p11.2      31630000    90354544   58724544  0.014388\n",
            "632     16    p11.2      31820000    90354544   58534544  0.007194\n",
            "634     16    p11.2      31850000    90354544   58504544  0.007194\n",
            "635     16    p11.2      31860000    90354544   58494544  0.067146\n",
            "636     16    p11.2      31873000    90354544   58481544  0.088729\n",
            "637     16    p11.2      31878000    90354544   58476544  0.016787\n",
            "638     16    p11.2      31882000    90354544   58472544  0.016787\n",
            "639     16    p11.2      31892000    90354544   58462544  0.016787\n",
            "642     16    p11.2      31957000    90354544   58397544  0.021583\n"
          ]
        }
      ]
    }
  ]
}