{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "analysis_of_cma_lcshsV2(IN DESENV).ipynb",
      "authorship_tag": "ABX9TyPUCgnKNsdWK16Hl3LTFvGA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tiagochavo87/LCSH_analysis/blob/main/analysis_of_cma_lcshsV2(IN_DESENV).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the data from the CSV file\n",
        "data = pd.read_csv(\"LOH3.csv\", sep=\";\")\n",
        "\n",
        "# Apply a filter to exclude chromosomes X and Y\n",
        "data = data.loc[(data['Chrom'] != 'X') & (data['Chrom'] != 'Y')]\n",
        "\n",
        "# Replace dots and convert Tamanho column to integer type\n",
        "data['Tamanho'] = data['Tamanho'].str.replace('.', '').astype(int)\n",
        "\n",
        "# Filter data for autosomes with a size greater than 10,000,000\n",
        "data_autosomes = data.loc[data['Chrom'].str.contains('^([1-9]|[1-9][0-9])$')]\n",
        "data_autosomes = data_autosomes[data_autosomes['Tamanho'] > 10000000]\n",
        "\n",
        "# Write the autosomes data to a new CSV file\n",
        "data_autosomes.to_csv('LCSHs_>_10.csv', sep=';', index=False)\n",
        "\n",
        "# Filter data for regions with size greater than or equal to 3,000,000\n",
        "data = data[data['Tamanho'] >= 3000000]\n",
        "\n",
        "# Filter data for regions with sizes between 3,000,000 and 5,000,000\n",
        "data_3_5 = data[(data['Tamanho'] > 3000000) & (data['Tamanho'] <= 5000000)]\n",
        "\n",
        "# Write the 3-5 MB regions data to a new CSV file\n",
        "data_3_5.to_csv('LCSHs_>_3_<_5.csv', sep=';', index=False)\n",
        "\n",
        "# Filter data for 3-5 MB regions with a total size of at least 10,000,000 and only one region per file\n",
        "data_3_5 = data_3_5.groupby('File').filter(lambda x: len(x) == 1 and x['Tamanho'].sum() >= 10000000)\n",
        "\n",
        "# Filter data for regions with size greater than 5,000,000\n",
        "data_5 = data[data['Tamanho'] > 5000000]\n",
        "\n",
        "# Filter data for regions with a total size of at least 10,000,000 and only one chromosome per file\n",
        "data_5 = data_5.groupby('File').filter(lambda x: len(x.groupby('Chrom')) == 1 and x['Tamanho'].sum() >= 10000000)\n",
        "\n",
        "# Write the 5 MB regions data to a new CSV file\n",
        "data_5.to_csv('possibles_UPDs.csv', sep=';', index=False)\n",
        "\n",
        "# Filter data for cases with at least one LCSH greater than 5 MB\n",
        "data_5_mb = data[data['Tamanho'] > 5000000]\n",
        "data_5_mb = data_5_mb.groupby('File').filter(lambda x: x[x['Tamanho'] >= 5000000].shape[0] > 0)\n",
        "\n",
        "# Print all cases with LCSHs greater than 5 MB to a CSV file\n",
        "data_5_mb.to_csv('LCSHs_>_5.csv', sep=';', index=False)\n",
        "\n",
        "# Sum LCSHs greater than 3 MB for each case\n",
        "sum_lcshs = data[data['Tamanho'] >= 3000000].groupby('File')['Tamanho'].sum()\n",
        "\n",
        "# Create a new DataFrame with case names and total LCSHs greater than 3 MB\n",
        "output = pd.DataFrame({'File': sum_lcshs.index, 'Total LCSHs > 3MB': sum_lcshs.values})\n",
        "\n",
        "# Write the output DataFrame to a CSV file\n",
        "output.to_csv('total_lcshs.csv', sep=';', index=False)\n",
        "\n",
        "# Calculate the total size of human autosomal DNA\n",
        "total_autosomal_dna = 2881000000\n",
        "\n",
        "# Calculate the proportion of LCSHs greater than 3 MB for each case\n",
        "proportions = []\n",
        "for file, size in sum_lcshs.items():\n",
        "    proportion = size / total_autosomal_dna\n",
        "    proportions.append({'File': file, 'Total LCSHs > 3MB': size, 'Proportion of LCSHs > 3MB to Autosomal DNA': proportion})\n",
        "\n",
        "# Create a new DataFrame with the proportion for each case\n",
        "proportions_df = pd.DataFrame(proportions)\n",
        "\n",
        "# Write the output DataFrame to a CSV file\n",
        "proportions_df.to_csv('lcsh_proportions.csv', sep=';', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRe5zTgCdZTP",
        "outputId": "987b9c29-2d1f-4442-bc87-e0bbd3098088"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-92-4174725c51df>:10: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  data['Tamanho'] = data['Tamanho'].str.replace('.', '').astype(int)\n",
            "<ipython-input-92-4174725c51df>:13: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
            "  data_autosomes = data.loc[data['Chrom'].str.contains('^([1-9]|[1-9][0-9])$')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code imports the NumPy and Pandas libraries and uses them to calculate inbreeding coefficients based on certain proportions of data.\n",
        "\n",
        "The first step is to define an array of values for F (inbreeding coefficient) that the code will use. These values are defined as percentages and then divided by 100.\n",
        "\n",
        "Next, the code reads in a CSV file containing proportions of data and stores them in a Pandas DataFrame.\n",
        "\n",
        "Then, the code iterates through each row of the DataFrame and calculates the F value that is closest to the proportion of LCSHs (Library of Congress Subject Headings) greater than 3MB to Autosomal DNA. This is done using NumPy's argmin() function to find the index of the closest F value in the array.\n",
        "\n",
        "After calculating the closest F value for each row, the code creates a new Pandas DataFrame with the data transposed so that the F values are columns and the file names are rows.\n",
        "\n",
        "Finally, the transposed DataFrame is written to a new CSV file along with the original proportions DataFrame.\n",
        "\n",
        "Overall, this code is useful for calculating inbreeding coefficients based on specific proportions of data, which can be helpful in genetic research.\n",
        "\n",
        "Output:\n",
        "There are two output files: 'lcsh_transposed_proportions.csv' and 'inbreeding_coefficients.csv'. The first file contains the transposed proportions DataFrame, and the second file contains the original proportions DataFrame with an additional column for the closest F value.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "amRV7uJM5-o7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the F values\n",
        "f_values = np.array([0.5, 1.5, 3, 6, 12.5, 25]) / 100\n",
        "\n",
        "# Get the data proportions\n",
        "proportions = pd.read_csv('lcsh_proportions.csv', sep=';')\n",
        "\n",
        "# Calculate the F values closest to the proportions\n",
        "for index, row in proportions.iterrows():\n",
        "    proportion = row['Proportion of LCSHs > 3MB to Autosomal DNA']\n",
        "    closest_f = f_values[np.abs(f_values - proportion).argmin()]\n",
        "    proportions.at[index, 'Inbreeding Coefficient (F)'] = closest_f\n",
        "\n",
        "# Transpose the cases to the columns corresponding to the F values\n",
        "transposed_proportions = pd.DataFrame(columns=['File', '0.5%', '1.5%', '3%', '6%', '12.5%', '25%'])\n",
        "for index, row in proportions.iterrows():\n",
        "    file = row['File']\n",
        "    f_value = row['Inbreeding Coefficient (F)']\n",
        "    transposed_proportions.at[index, 'File'] = file\n",
        "    transposed_proportions.at[index, f'{f_value*100:.1f}%'] = row['Proportion of LCSHs > 3MB to Autosomal DNA']\n",
        "\n",
        "# Write the transposed DataFrame to a new CSV file\n",
        "transposed_proportions.to_csv('lcsh_transposed_proportions.csv', sep=';', index=False)\n",
        "\n",
        "# Write the output DataFrame to a CSV file\n",
        "proportions.to_csv('inbreeding_coefficients.csv', sep=';', index=False)\n"
      ],
      "metadata": {
        "id": "lzniRUaB3mQ2"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Carrega tabela de dados\n",
        "df = pd.read_csv(\"LCSHs_>_3_<_5.csv\", sep=\";\")\n",
        "\n",
        "# Extrai coordenadas genômicas da coluna 'Microarray Nome..'\n",
        "chrom_pos = []\n",
        "for name in df['Microarray Nome..']:\n",
        "    match = re.search(r'\\d+[pq]\\d+(\\.\\d+)?[pq]\\d+(\\.\\d+)?\\((\\d+)-(\\d+)\\)', name)\n",
        "    if match:\n",
        "        chrom, start, end = match.group(0).split()[1].split('(')[0].split('-')\n",
        "        chrom_pos.append((chrom, int(start), int(end)))\n",
        "    else:\n",
        "        chrom_pos.append(None)\n",
        "df['chrom_pos'] = chrom_pos\n",
        "\n",
        "# Divide coordenadas por cromossomos\n",
        "chrom_dict = {}\n",
        "for chrom_pos_tuple in chrom_pos:\n",
        "    if chrom_pos_tuple:\n",
        "        chrom, start, end = chrom_pos_tuple\n",
        "        if chrom not in chrom_dict:\n",
        "            chrom_dict[chrom] = []\n",
        "        chrom_dict[chrom].append((start, end))\n",
        "\n",
        "# Loop pelos cromossomos\n",
        "threshold = 0.02  # Fração mínima de amostras com trechos de homozygose\n",
        "homozygous_dict = {}\n",
        "for chrom, coords in chrom_dict.items():\n",
        "    total_samples = len(df)\n",
        "    \n",
        "    # Filtra amostras apenas para o cromossomo atual\n",
        "    chrom_df = df[df['chrom_pos'].apply(lambda x: x[0] if x else None) == chrom]\n",
        "    \n",
        "    homozygous_samples = 0\n",
        "    window_size = 1000000  # Tamanho da janela para detecção de trechos de homozygose\n",
        "    for start, end in coords:\n",
        "        window_start = start\n",
        "        while window_start < end:\n",
        "            window_end = min(window_start + window_size, end)\n",
        "            samples = chrom_df[(chrom_df['chrom_pos'] == (chrom, window_start, window_end)) & (chrom_df['Call Rate'] >= 0.95)]\n",
        "            if len(samples) > 0 and all(samples['B Allele Freq'].round(2).duplicated()):\n",
        "                homozygous_samples += len(samples)\n",
        "            window_start = window_end\n",
        "    homozygous_fraction = homozygous_samples / len(chrom_df)\n",
        "    if homozygous_fraction > threshold:\n",
        "        homozygous_dict[chrom] = homozygous_fraction\n",
        "\n",
        "# Gera nova tabela CSV com informações de cromossomos e frações de amostras com trechos de homozygose\n",
        "homozygous_df = pd.DataFrame({'Chromosome': list(homozygous_dict.keys()), 'Homozygous Fraction': list(homozygous_dict.values())})\n",
        "homozygous_df.to_csv('homozygous_regions4.csv', index=False)\n"
      ],
      "metadata": {
        "id": "DUfC-U5LM2w1"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Carrega o arquivo CSV\n",
        "df = pd.read_csv(\"LCSHs_>_3_<_5.csv\", sep=\";\")\n",
        "# Extrai as informações da coluna \"Microarray Nome..\"\n",
        "df['start'] = df['Microarray Nome..'].str.extract('\\((.*?)\\-')\n",
        "df['end'] = df['Microarray Nome..'].str.extract('\\-(.*?)\\)')\n",
        "\n",
        "def extract_coordinates(row):\n",
        "    pattern = r'\\((\\d+,?\\d*)-(\\d+,?\\d*)\\)'\n",
        "    match = re.search(pattern, row)\n",
        "    if match:\n",
        "        start = match.group(1).replace(',', '.')\n",
        "        end = match.group(2).replace(',', '.')\n",
        "        return pd.Series([start, end])\n",
        "    else:\n",
        "        return pd.Series(['', ''])\n",
        "\n",
        "# Remove a coluna original\n",
        "df.drop('Microarray Nome..', axis=1, inplace=True)\n",
        "\n",
        "# Cria uma nova dataframe com as colunas \"Chrom\", \"cytoband\", \"start\" e \"end\"\n",
        "new_df = pd.DataFrame({\n",
        "    'Chrom': df['Chrom'],\n",
        "    'cytoband': df['cytoband'],\n",
        "    'start': df['start'],\n",
        "    'end': df['end']\n",
        "})\n",
        "\n",
        "def extract_coordinates(row):\n",
        "    pattern = r'\\((\\d+,?\\d*)-(\\d+,?\\d*)\\)'\n",
        "    match = re.search(pattern, row)\n",
        "    if match:\n",
        "        start = match.group(1).replace(',', '.')\n",
        "        end = match.group(2).replace(',', '.')\n",
        "        return pd.Series([start, end])\n",
        "    else:\n",
        "        return pd.Series(['', ''])\n",
        "\n",
        "new_df['start'] = new_df['start'].replace(',', '', regex=True)\n",
        "new_df['end'] = new_df['end'].replace(',', '', regex=True)\n",
        "\n",
        "# Salva a nova dataframe em um arquivo CSV\n",
        "new_df.to_csv('nova_dataframe_fron.csv', sep=\";\", index=False, decimal='.')\n",
        "\n"
      ],
      "metadata": {
        "id": "OLmIC-EGVIaH"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P1_mdSw1PYvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjZPx6gCN--c",
        "outputId": "c703e457-bddb-4a3f-9e08-da5a465e7099"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   chrom  start        end  n_windows\n",
            "0      1      0  249250621     249250\n",
            "1      2      0  243199373     243199\n",
            "2      3      0  198022430     198022\n",
            "3      4      0  191154276     191154\n",
            "4      5      0  180915260     180915\n",
            "5      6      0  171115067     171115\n",
            "6      7      0  159138663     159138\n",
            "7      8      0  146364022     146364\n",
            "8      9      0  141213431     141213\n",
            "9     10      0  135534747     135534\n",
            "10    11      0  135006516     135006\n",
            "11    12      0  133851895     133851\n",
            "12    13      0  115169878     115169\n",
            "13    14      0  107349540     107349\n",
            "14    15      0  102531392     102531\n",
            "15    16      0   90354753      90354\n",
            "16    17      0   81195210      81195\n",
            "17    18      0   78077248      78077\n",
            "18    19      0   59128983      59128\n",
            "19    20      0   63025520      63025\n",
            "20    21      0   48129895      48129\n",
            "21    22      0   51304566      51304\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Definir um dicionário com as informações de início e fim de cada cromossomo\n",
        "chromosomes = {\n",
        "    'chr1': {'start': 0, 'end': 249250621},\n",
        "    'chr2': {'start': 0, 'end': 243199373},\n",
        "    'chr3': {'start': 0, 'end': 198022430},\n",
        "    'chr4': {'start': 0, 'end': 191154276},\n",
        "    'chr5': {'start': 0, 'end': 180915260},\n",
        "    'chr6': {'start': 0, 'end': 171115067},\n",
        "    'chr7': {'start': 0, 'end': 159138663},\n",
        "    'chr8': {'start': 0, 'end': 146364022},\n",
        "    'chr9': {'start': 0, 'end': 141213431},\n",
        "    'chr10': {'start': 0, 'end': 135534747},\n",
        "    'chr11': {'start': 0, 'end': 135006516},\n",
        "    'chr12': {'start': 0, 'end': 133851895},\n",
        "    'chr13': {'start': 0, 'end': 115169878},\n",
        "    'chr14': {'start': 0, 'end': 107349540},\n",
        "    'chr15': {'start': 0, 'end': 102531392},\n",
        "    'chr16': {'start': 0, 'end': 90354753},\n",
        "    'chr17': {'start': 0, 'end': 81195210},\n",
        "    'chr18': {'start': 0, 'end': 78077248},\n",
        "    'chr19': {'start': 0, 'end': 59128983},\n",
        "    'chr20': {'start': 0, 'end': 63025520},\n",
        "    'chr21': {'start': 0, 'end': 48129895},\n",
        "    'chr22': {'start': 0, 'end': 51304566},\n",
        "}\n",
        "\n",
        "# Criar uma DataFrame a partir do dicionário de cromossomos e adicionar o cabeçalho \"chrom\" à coluna de índices\n",
        "chromosomes_df = pd.DataFrame.from_dict(chromosomes, orient='index', columns=['start', 'end'])\n",
        "chromosomes_df = chromosomes_df.rename_axis('chrom').reset_index()\n",
        "# Substituir \"chr\" pelo valor numérico do cromossomo na coluna \"chrom\"\n",
        "chromosomes_df['chrom'] = chromosomes_df['chrom'].replace('chr', '', regex=True)\n",
        "# Definir a janela de análise como sendo de 1 kilobase (1000 pares de base)\n",
        "window_size = 1000\n",
        "chromosomes_df['n_windows'] = ((chromosomes_df['end'] - chromosomes_df['start']) / window_size).astype(int)\n",
        "\n",
        "print(chromosomes_df)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chrom_df)"
      ],
      "metadata": {
        "id": "QnEf1IZFWgJN",
        "outputId": "ed0b864b-f4f9-4ffc-adf3-051737b2cf06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Chrom cytoband      start        end  Frequency\n",
            "173      3   p21.31   46484498   51474182        0.0\n",
            "174      3    q22.2  135293279  140278952        0.0\n",
            "175      3   p21.31   48531739   53234994        0.0\n",
            "176      3   p21.31   47868563   52569949        0.0\n",
            "177      3   p21.31   46480701   51095279        0.0\n",
            "..     ...      ...        ...        ...        ...\n",
            "232      3   p21.31   50202312   53234057        0.0\n",
            "233      3   p21.31   50088300   53101580        0.0\n",
            "234      3   p21.31   49878112   52889771        0.0\n",
            "235      3    q22.2  135621103  138632108        0.0\n",
            "236      3   p21.31   50202312   53212716        0.0\n",
            "\n",
            "[64 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ler o arquivo CSV\n",
        "data = pd.read_csv('LOH3.csv', sep=';')\n",
        "\n",
        "# Contar a quantidade de valores únicos na coluna \"File\"\n",
        "file_count = data['File'].nunique()\n",
        "\n",
        "# Imprimir o total de casos \"File\"\n",
        "print(f\"O total de casos na coluna 'File' é: {file_count}\")\n",
        "\n",
        "# Armazenar o resultado em uma variável\n",
        "result = pd.DataFrame({'Total de casos': [file_count]})\n",
        "\n",
        "# Salvar o resultado em um arquivo CSV\n",
        "result.to_csv('output.csv', index=False)\n",
        "\n",
        "# Imprimir o resultado\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "Mt-d62ocmygS",
        "outputId": "815c353f-3ebb-47a5-9c09-0554abfd0c81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O total de casos na coluna 'File' é: 371\n",
            "   Total de casos\n",
            "0             371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ler o arquivo nova_dataframe_fron6.csv\n",
        "df = pd.read_csv('nova_dataframe_fron6.csv', sep=\";\", decimal='.')\n",
        "\n",
        "# Renomear as colunas\n",
        "df = df.rename(columns={'Chrom': 'chrom', 'start': 'start_pos', 'end': 'end_pos'})\n",
        "# Mesclar as informações dos cromossomos com as coordenadas genômicas\n",
        "chromosomes_df['chrom'] = chromosomes_df['chrom'].astype(int)\n",
        "\n",
        "merged_df = pd.merge(df, chromosomes_df, on='chrom', how='inner')\n",
        "# Calcular as regiões genômicas de interesse\n",
        "merged_df['start_region'] = merged_df['start'] + ((merged_df['start_pos'] - 1) // window_size) * window_size\n",
        "merged_df['end_region'] = merged_df['end'] - (merged_df['end'] - merged_df['end_pos']) % window_size\n",
        "# Selecionar as colunas de interesse\n",
        "result2 = merged_df[['chrom', 'cytoband', 'start_region', 'end_region']]\n",
        "\n",
        "# Salvar o resultado em um arquivo CSV\n",
        "result2.to_csv('output_regions.csv', sep= \";\")\n"
      ],
      "metadata": {
        "id": "1A5jl1knBUgA"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ler o arquivo de saída anterior com as regiões genômicas\n",
        "regions = pd.read_csv('output_regions.csv', sep=';')\n",
        "\n",
        "# Contar a ocorrência de cada região genômica\n",
        "counts = regions.value_counts(['chrom', 'start_region', 'end_region'])\n",
        "\n",
        "# Obter o total de casos\n",
        "total_cases = pd.read_csv('output.csv')['Total de casos'][0]\n",
        "\n",
        "# Calcular a frequência relativa de cada região genômica\n",
        "freq = counts / total_cases\n",
        "\n",
        "# Salvar o resultado em um arquivo CSV\n",
        "freq.to_csv('output_frequency.csv', sep=';')\n"
      ],
      "metadata": {
        "id": "H9vdDgbkEdK5"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular a frequência de cada região genômica\n",
        "freq = result2.groupby(['chrom', 'start_region', 'end_region']).size().reset_index(name='frequencia')\n",
        "freq['frequencia'] = freq['frequencia'] / file_count\n",
        "\n",
        "# Selecionar as regiões com frequência igual ou maior que 5%\n",
        "freq_5 = freq[freq['frequencia'] >= 0.005]\n",
        "\n",
        "# Salvar o resultado em um arquivo CSV\n",
        "freq_5.to_csv('output_freq_5.csv', sep=';', index=False)\n"
      ],
      "metadata": {
        "id": "gYCk79WGFAoJ"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(freq_5)"
      ],
      "metadata": {
        "id": "ShQ9Z6fpsU5d",
        "outputId": "3806ce8a-a3f6-4311-d2a8-11883028c642",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     chrom  start_region  end_region  frequencia\n",
            "46       1     144077000   249250533    0.029650\n",
            "49       1     146881000   249250352    0.005391\n",
            "87       1     147385000   249250414    0.005391\n",
            "100      2      55365000   243198887    0.005391\n",
            "111      2      95341000   243198461    0.005391\n",
            "116      2      95341000   243198664    0.008086\n",
            "117      2      95341000   243198711    0.005391\n",
            "126      2      95550000   243198972    0.005391\n",
            "128      2      95550000   243199110    0.005391\n",
            "134      2     130732000   243199078    0.005391\n",
            "203      3      93558000   198022166    0.005391\n"
          ]
        }
      ]
    }
  ]
}