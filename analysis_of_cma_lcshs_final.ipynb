{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://gist.github.com/tiagochavo87/85fc2bce642ef04735cd531aa0ee2de1#file-analysis_of_cma_lcshs-ipynb",
      "authorship_tag": "ABX9TyMnZa4tOC6TextCRGxtJJX9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tiagochavo87/LCSH_analysis/blob/main/analysis_of_cma_lcshs_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the data from the CSV file\n",
        "data = pd.read_csv(\"LOHx.csv\", sep=\";\")\n",
        "\n",
        "# Apply a filter to exclude chromosomes X and Y\n",
        "data = data.loc[(data['Chrom'] != 'X') & (data['Chrom'] != 'Y')]\n",
        "\n",
        "# Replace dots and convert Tamanho column to integer type\n",
        "data['Tamanho'] = data['Tamanho'].str.replace('.', '').astype(int)\n",
        "\n",
        "# Filter data for autosomes with a size greater than 10,000,000\n",
        "data_autosomes = data.loc[data['Chrom'].str.contains('^([1-9]|[1-9][0-9])$')]\n",
        "data_autosomes = data_autosomes[data_autosomes['Tamanho'] > 10000000]\n",
        "\n",
        "# Write the autosomes data to a new CSV file\n",
        "data_autosomes.to_csv('LCSHs_>_10.csv', sep=';', index=False)\n",
        "\n",
        "# Filter data for regions with size greater than or equal to 3,000,000\n",
        "data = data[data['Tamanho'] >= 3000000]\n",
        "\n",
        "# Filter data for regions with sizes between 3,000,000 and 5,000,000\n",
        "data_3_5 = data[(data['Tamanho'] > 3000000) & (data['Tamanho'] <= 5000000)]\n",
        "\n",
        "# Write the 3-5 MB regions data to a new CSV file\n",
        "data_3_5.to_csv('LCSHs_>_3_<_5.csv', sep=';', index=False)\n",
        "\n",
        "# Filter data for 3-5 MB regions with a total size of at least 10,000,000 and only one region per file\n",
        "data_3_5 = data_3_5.groupby('File').filter(lambda x: len(x) == 1 and x['Tamanho'].sum() >= 10000000)\n",
        "\n",
        "# Filter data for regions with size greater than 5,000,000\n",
        "data_5 = data[data['Tamanho'] > 5000000]\n",
        "\n",
        "# Filter data for regions with a total size of at least 10,000,000 and only one chromosome per file\n",
        "data_5 = data_5.groupby('File').filter(lambda x: len(x.groupby('Chrom')) == 1 and x['Tamanho'].sum() >= 10000000)\n",
        "\n",
        "# Write the 5 MB regions data to a new CSV file\n",
        "data_5.to_csv('possibles_UPDs.csv', sep=';', index=False)\n",
        "\n",
        "# Filter data for cases with at least one LCSH greater than 5 MB\n",
        "data_5_mb = data[data['Tamanho'] > 5000000]\n",
        "data_5_mb = data_5_mb.groupby('File').filter(lambda x: x[x['Tamanho'] >= 5000000].shape[0] > 0)\n",
        "\n",
        "# Print all cases with LCSHs greater than 5 MB to a CSV file\n",
        "data_5_mb.to_csv('LCSHs_>_5.csv', sep=';', index=False)\n",
        "\n",
        "# Sum LCSHs greater than 3 MB for each case\n",
        "sum_lcshs = data[data['Tamanho'] >= 3000000].groupby('File')['Tamanho'].sum()\n",
        "\n",
        "# Create a new DataFrame with case names and total LCSHs greater than 3 MB\n",
        "output = pd.DataFrame({'File': sum_lcshs.index, 'Total LCSHs > 3MB': sum_lcshs.values})\n",
        "\n",
        "# Write the output DataFrame to a CSV file\n",
        "output.to_csv('total_lcshs.csv', sep=';', index=False)\n",
        "\n",
        "# Calculate the total size of human autosomal DNA\n",
        "total_autosomal_dna = 2881000000\n",
        "\n",
        "# Calculate the proportion of LCSHs greater than 3 MB for each case\n",
        "proportions = []\n",
        "for file, size in sum_lcshs.items():\n",
        "    proportion = size / total_autosomal_dna\n",
        "    proportions.append({'File': file, 'Total LCSHs > 3MB': size, 'Proportion of LCSHs > 3MB to Autosomal DNA': proportion})\n",
        "\n",
        "# Create a new DataFrame with the proportion for each case\n",
        "proportions_df = pd.DataFrame(proportions)\n",
        "\n",
        "# Write the output DataFrame to a CSV file\n",
        "proportions_df.to_csv('lcsh_proportions.csv', sep=';', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRe5zTgCdZTP",
        "outputId": "320b9166-6147-4263-fe99-1755a6c519a5"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-98-4b4fab267ef6>:10: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  data['Tamanho'] = data['Tamanho'].str.replace('.', '').astype(int)\n",
            "<ipython-input-98-4b4fab267ef6>:13: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  data_autosomes = data.loc[data['Chrom'].str.contains('^([1-9]|[1-9][0-9])$')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code imports the NumPy and Pandas libraries and uses them to calculate inbreeding coefficients based on certain proportions of data.\n",
        "\n",
        "The first step is to define an array of values for F (inbreeding coefficient) that the code will use. These values are defined as percentages and then divided by 100.\n",
        "\n",
        "Next, the code reads in a CSV file containing proportions of data and stores them in a Pandas DataFrame.\n",
        "\n",
        "Then, the code iterates through each row of the DataFrame and calculates the F value that is closest to the proportion of LCSHs (Library of Congress Subject Headings) greater than 3MB to Autosomal DNA. This is done using NumPy's argmin() function to find the index of the closest F value in the array.\n",
        "\n",
        "After calculating the closest F value for each row, the code creates a new Pandas DataFrame with the data transposed so that the F values are columns and the file names are rows.\n",
        "\n",
        "Finally, the transposed DataFrame is written to a new CSV file along with the original proportions DataFrame.\n",
        "\n",
        "Overall, this code is useful for calculating inbreeding coefficients based on specific proportions of data, which can be helpful in genetic research.\n",
        "\n",
        "Output:\n",
        "There are two output files: 'lcsh_transposed_proportions.csv' and 'inbreeding_coefficients.csv'. The first file contains the transposed proportions DataFrame, and the second file contains the original proportions DataFrame with an additional column for the closest F value.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "amRV7uJM5-o7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the F values\n",
        "f_values = np.array([0.5, 1.5, 3, 6, 12.5, 25]) / 100\n",
        "\n",
        "# Get the data proportions\n",
        "proportions = pd.read_csv('lcsh_proportions.csv', sep=';')\n",
        "\n",
        "# Calculate the F values closest to the proportions\n",
        "for index, row in proportions.iterrows():\n",
        "    proportion = row['Proportion of LCSHs > 3MB to Autosomal DNA']\n",
        "    closest_f = f_values[np.abs(f_values - proportion).argmin()]\n",
        "    proportions.at[index, 'Inbreeding Coefficient (F)'] = closest_f\n",
        "\n",
        "# Transpose the cases to the columns corresponding to the F values\n",
        "transposed_proportions = pd.DataFrame(columns=['File', '0.5%', '1.5%', '3%', '6%', '12.5%', '25%'])\n",
        "for index, row in proportions.iterrows():\n",
        "    file = row['File']\n",
        "    f_value = row['Inbreeding Coefficient (F)']\n",
        "    transposed_proportions.at[index, 'File'] = file\n",
        "    transposed_proportions.at[index, f'{f_value*100:.1f}%'] = row['Proportion of LCSHs > 3MB to Autosomal DNA']\n",
        "\n",
        "# Write the transposed DataFrame to a new CSV file\n",
        "transposed_proportions.to_csv('lcsh_transposed_proportions.csv', sep=';', index=False)\n",
        "\n",
        "# Write the output DataFrame to a CSV file\n",
        "proportions.to_csv('inbreeding_coefficients.csv', sep=';', index=False)\n"
      ],
      "metadata": {
        "id": "lzniRUaB3mQ2"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Carrega o arquivo CSV\n",
        "df = pd.read_csv(\"LCSHs_>_3_<_5.csv\", sep=\";\")\n",
        "# Extrai as informações da coluna \"Microarray Nome..\"\n",
        "df['start'] = df['Microarray Nome..'].str.extract('\\((.*?)\\-')\n",
        "df['end'] = df['Microarray Nome..'].str.extract('\\-(.*?)\\)')\n",
        "\n",
        "def extract_coordinates(row):\n",
        "    pattern = r'\\((\\d+,?\\d*)-(\\d+,?\\d*)\\)'\n",
        "    match = re.search(pattern, row)\n",
        "    if match:\n",
        "        start = match.group(1).replace(',', '.')\n",
        "        end = match.group(2).replace(',', '.')\n",
        "        return pd.Series([start, end])\n",
        "    else:\n",
        "        return pd.Series(['', ''])\n",
        "\n",
        "# Remove a coluna original\n",
        "df.drop('Microarray Nome..', axis=1, inplace=True)\n",
        "\n",
        "# Cria uma nova dataframe com as colunas \"Chrom\", \"cytoband\", \"start\" e \"end\"\n",
        "new_df = pd.DataFrame({\n",
        "    'Chrom': df['Chrom'],\n",
        "    'cytoband': df['cytoband'],\n",
        "    'start': df['start'],\n",
        "    'end': df['end']\n",
        "})\n",
        "\n",
        "def extract_coordinates(row):\n",
        "    pattern = r'\\((\\d+,?\\d*)-(\\d+,?\\d*)\\)'\n",
        "    match = re.search(pattern, row)\n",
        "    if match:\n",
        "        start = match.group(1).replace(',', '.')\n",
        "        end = match.group(2).replace(',', '.')\n",
        "        return pd.Series([start, end])\n",
        "    else:\n",
        "        return pd.Series(['', ''])\n",
        "\n",
        "new_df['start'] = new_df['start'].replace(',', '', regex=True)\n",
        "new_df['end'] = new_df['end'].replace(',', '', regex=True)\n",
        "\n",
        "# Salva a nova dataframe em um arquivo CSV\n",
        "new_df.to_csv('nova_dataframe_fron.csv', sep=\";\", index=False, decimal='.')\n",
        "\n"
      ],
      "metadata": {
        "id": "OLmIC-EGVIaH"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ler o arquivo CSV\n",
        "data = pd.read_csv('LOHx.csv', sep=';')\n",
        "\n",
        "# Contar a quantidade de valores únicos na coluna \"File\"\n",
        "file_count = data['File'].nunique()\n",
        "\n",
        "# Imprimir o total de casos \"File\"\n",
        "print(f\"O total de casos na coluna 'File' é: {file_count}\")\n",
        "\n",
        "# Armazenar o resultado em uma variável\n",
        "result0 = pd.DataFrame([file_count])\n",
        "\n",
        "# Salvar o resultado em um arquivo CSV\n",
        "result0.to_csv('output.csv', sep=';', index=False)\n",
        "\n",
        "# Imprimir o resultado\n",
        "print(result0)\n"
      ],
      "metadata": {
        "id": "Mt-d62ocmygS",
        "outputId": "4823fcce-e534-4023-a8dc-6a4f0541f92d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O total de casos na coluna 'File' é: 917\n",
            "     0\n",
            "0  917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ler arquivo de entrada (assumindo que esteja em formato csv)\n",
        "df = pd.read_csv('nova_dataframe_fron.csv', sep=\";\")\n",
        "result = 917\n",
        "\n",
        "# Agrupar por cromossomo e citobanda, incluindo o número de cromossomo na agregação\n",
        "grouped_df = df.groupby(['Chrom', 'cytoband']).agg({'start': 'median', 'end': 'median', 'Chrom': ['count', 'first']})\n",
        "\n",
        "# Renomear colunas\n",
        "grouped_df.columns = ['start', 'end', 'frequency', 'Chrom']\n",
        "\n",
        "# Normalizar frequência em relação a um valor de referência\n",
        "grouped_df['normalized_frequency'] = grouped_df['frequency'] / result\n",
        "\n",
        "# Salvar resultado em um novo arquivo csv\n",
        "grouped_df.to_csv('resultado.csv', index=False)\n",
        "\n",
        "# Encontrar casos com frequência absoluta maior que 5%\n",
        "frequencia_absoluta = grouped_df[grouped_df['frequency'] >= 0.005 * len(df)]\n",
        "\n",
        "# Salvar casos em um novo arquivo csv\n",
        "frequencia_absoluta.to_csv('frequencia_absoluta.csv', sep=\";\", index=True, decimal='.')\n"
      ],
      "metadata": {
        "id": "IvgOG6LjNPF8"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ler arquivo de entrada (assumindo que esteja em formato csv)\n",
        "df = pd.read_csv('nova_dataframe_fron.csv', sep=\";\")\n",
        "result = 917\n",
        "\n",
        "# Agrupar por cromossomo e citobanda, incluindo o número de cromossomo na agregação\n",
        "grouped_df = df.groupby(['Chrom', 'cytoband']).agg({'start': 'median', 'end': 'median', 'Chrom': ['count', 'first']})\n",
        "\n",
        "# Renomear colunas\n",
        "grouped_df.columns = ['start', 'end', 'frequency', 'Chrom']\n",
        "\n",
        "# Normalizar frequência em relação a um valor de referência\n",
        "grouped_df['normalized_frequency'] = grouped_df['frequency'] / result\n",
        "\n",
        "# Formatar as colunas 'start' e 'end'\n",
        "grouped_df[['start', 'end']] = grouped_df[['start', 'end']].astype(int).applymap('{:09d}'.format)\n",
        "\n",
        "\n",
        "# Salvar resultado em um novo arquivo csv\n",
        "grouped_df.to_csv('resultado.csv', index=False)\n",
        "\n",
        "# Encontrar casos com frequência absoluta maior que 5%\n",
        "frequencia_absoluta = grouped_df[grouped_df['frequency'] >= 0.005 * len(df)]\n",
        "# Arredondar colunas start, end e normalized_frequency\n",
        "frequencia_absoluta['normalized_frequency'] = frequencia_absoluta['normalized_frequency'].round(decimals=3)\n",
        "\n",
        "# Salvar casos em um novo arquivo csv\n",
        "frequencia_absoluta.to_csv('frequencia_absoluta.csv', sep=\";\", index=True, decimal='.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGfq9jgGT-1J",
        "outputId": "920cde02-e194-4890-f9da-0913cab07cae"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-110-9f7aa87ac9b0>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  frequencia_absoluta['normalized_frequency'] = frequencia_absoluta['normalized_frequency'].round(decimals=3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_5bDEGrkRahb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Ler arquivo de entrada (assumindo que esteja em formato csv)\n",
        "df = pd.read_csv('nova_dataframe_fron.csv', sep=\";\")\n",
        "result = 917\n",
        "\n",
        "# Agrupar por cromossomo e citobanda, incluindo o número de cromossomo na agregação\n",
        "grouped_df = df.groupby(['Chrom', 'cytoband']).agg({'start': 'median', 'end': 'median', 'Chrom': ['count', 'first']})\n",
        "\n",
        "# Renomear colunas\n",
        "grouped_df.columns = ['start', 'end', 'frequency', 'Chrom']\n",
        "\n",
        "# Normalizar frequência em relação a um valor de referência\n",
        "grouped_df['normalized_frequency'] = grouped_df['frequency'] / result\n",
        "\n",
        "# Formatar as colunas 'start' e 'end'\n",
        "grouped_df[['start', 'end']] = grouped_df[['start', 'end']].astype(int).applymap('{:09d}'.format)\n",
        "\n",
        "# Calcular tamanho em Kilobases de base\n",
        "grouped_df['Size'] = ((grouped_df['end'].astype(int) - grouped_df['start'].astype(int)) / 1000).astype(int)\n",
        "\n",
        "# Salvar resultado em um novo arquivo csv\n",
        "grouped_df.to_csv('resultado.csv', index=False)\n",
        "\n",
        "# Encontrar casos com frequência absoluta maior que 5%\n",
        "frequencia_absoluta = grouped_df[grouped_df['frequency'] >= 0.005 * len(df)]\n",
        "\n",
        "# Arredondar colunas start, end e normalized_frequency\n",
        "frequencia_absoluta['normalized_frequency'] = frequencia_absoluta['normalized_frequency'].round(decimals=3)\n",
        "\n",
        "# Salvar casos em um novo arquivo csv\n",
        "frequencia_absoluta.to_csv('frequencia_absoluta.csv', sep=\";\", index=True, decimal='.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkoCsUgRXrll",
        "outputId": "9ea1040b-f580-401d-b97c-1ef674eff0d2"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-115-a23bf8fd2112>:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  frequencia_absoluta['normalized_frequency'] = frequencia_absoluta['normalized_frequency'].round(decimals=3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(frequencia_absoluta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TW8AoOkuNh5M",
        "outputId": "d7faded9-a27c-4d3f-8104-c6da426fba64"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    start        end  frequency  Chrom  normalized_frequency  \\\n",
            "Chrom cytoband                                                                 \n",
            "1     p33       049149495  053138197         82      1                 0.089   \n",
            "      q21.1     144077594  148750533         52      1                 0.057   \n",
            "      q21.2     147268778  150579272         56      1                 0.061   \n",
            "2     q11.1     095550958  098905554         61      2                 0.067   \n",
            "      q32.1     187305881  190929980         19      2                 0.021   \n",
            "      q32.3     193761737  197779433         22      2                 0.024   \n",
            "3     p21.31    048597552  052514732        120      3                 0.131   \n",
            "4     p15.1     032356205  035680350         20      4                 0.022   \n",
            "5     p12       043046912  046313469         21      5                 0.023   \n",
            "      q23.3     128694241  132201418         45      5                 0.049   \n",
            "6     p22.2     026290480  029543646         38      6                 0.041   \n",
            "      q11.1     061972918  065334455         21      6                 0.023   \n",
            "7     q11.21    062569502  066804740         30      7                 0.033   \n",
            "      q11.22    071877057  075272042         34      7                 0.037   \n",
            "      q11.23    072982873  076892029         19      7                 0.021   \n",
            "      q31.31    117669467  121109647         13      7                 0.014   \n",
            "8     q11.1     046919157  050833528         19      8                 0.021   \n",
            "10    p12.31    021073956  024288819         16     10                 0.017   \n",
            "      q11.21    045478681  049450781         17     10                 0.019   \n",
            "      q22.1     073953260  077200441         79     10                 0.086   \n",
            "11    p11.2     047885574  051550787        160     11                 0.174   \n",
            "      q13.1     065079920  068434181         20     11                 0.022   \n",
            "      q13.4     071201937  074491086         14     11                 0.015   \n",
            "12    q24.11    110123120  113211471         42     12                 0.046   \n",
            "15    q15.1     042335561  045773925         81     15                 0.088   \n",
            "16    p11.2     031609107  035220544        305     16                 0.333   \n",
            "      q21       066299654  069595736         20     16                 0.022   \n",
            "17    q11.2     027524805  030869940         19     17                 0.021   \n",
            "      q22       056100878  059323221         33     17                 0.036   \n",
            "19    p13.2     009317864  012975314         23     19                 0.025   \n",
            "      q13.2     040357663  044200928         47     19                 0.051   \n",
            "20    q11.21    031711686  035459439         31     20                 0.034   \n",
            "      q11.22    032603829  036081725         23     20                 0.025   \n",
            "\n",
            "                Size  \n",
            "Chrom cytoband        \n",
            "1     p33       3988  \n",
            "      q21.1     4672  \n",
            "      q21.2     3310  \n",
            "2     q11.1     3354  \n",
            "      q32.1     3624  \n",
            "      q32.3     4017  \n",
            "3     p21.31    3917  \n",
            "4     p15.1     3324  \n",
            "5     p12       3266  \n",
            "      q23.3     3507  \n",
            "6     p22.2     3253  \n",
            "      q11.1     3361  \n",
            "7     q11.21    4235  \n",
            "      q11.22    3394  \n",
            "      q11.23    3909  \n",
            "      q31.31    3440  \n",
            "8     q11.1     3914  \n",
            "10    p12.31    3214  \n",
            "      q11.21    3972  \n",
            "      q22.1     3247  \n",
            "11    p11.2     3665  \n",
            "      q13.1     3354  \n",
            "      q13.4     3289  \n",
            "12    q24.11    3088  \n",
            "15    q15.1     3438  \n",
            "16    p11.2     3611  \n",
            "      q21       3296  \n",
            "17    q11.2     3345  \n",
            "      q22       3222  \n",
            "19    p13.2     3657  \n",
            "      q13.2     3843  \n",
            "20    q11.21    3747  \n",
            "      q11.22    3477  \n"
          ]
        }
      ]
    }
  ]
}